{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-07T09:43:49.355804Z",
     "start_time": "2025-07-07T09:43:44.730724Z"
    }
   },
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "def match_queries_by_topic(\n",
    "    docs_topic_path: str,\n",
    "    docs_embedding_path: str,\n",
    "    queries_embedding_path: str,\n",
    "    output_path: str = \"bert_topic_results.json\",\n",
    "    top_k: int = 100\n",
    "):\n",
    "    print(\"ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª BERTopic + BERT embeddings Ù„Ù„ÙˆØ«Ø§Ø¦Ù‚...\")\n",
    "    topic_data = joblib.load(docs_topic_path)\n",
    "    bert_data = joblib.load(docs_embedding_path)\n",
    "    query_data = joblib.load(queries_embedding_path)\n",
    "\n",
    "    doc_ids = bert_data[\"doc_ids\"]\n",
    "    doc_embeddings = np.vstack(bert_data[\"embeddings_matrix\"])\n",
    "\n",
    "    query_ids = query_data[\"query_ids\"]\n",
    "    query_embeddings = np.vstack(query_data[\"embeddings\"])\n",
    "\n",
    "    topics = topic_data[\"topics\"]\n",
    "    topic_embeddings = topic_data[\"topic_embeddings\"]\n",
    "    topic_ids = list(topic_embeddings.keys())\n",
    "    topic_vectors = np.array([topic_embeddings[tid] for tid in topic_ids])\n",
    "\n",
    "    print(f\"ğŸ§  Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØ¨ÙŠÙƒØ§Øª: {len(topic_ids)}\")\n",
    "    print(f\"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª: {len(query_ids)}, Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚: {len(doc_ids)}\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for i, query_embedding in tqdm(enumerate(query_embeddings), total=len(query_embeddings), desc=\"ğŸ” Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª\"):\n",
    "        query_id = query_ids[i]\n",
    "\n",
    "        # 1ï¸âƒ£ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØªÙˆØ¨ÙŠÙƒ Ø§Ù„Ø£ÙØ¶Ù„\n",
    "        topic_similarities = cosine_similarity([query_embedding], topic_vectors)[0]\n",
    "        best_topic_index = np.argmax(topic_similarities)\n",
    "        predicted_topic = topic_ids[best_topic_index]\n",
    "\n",
    "        # 2ï¸âƒ£ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø¶Ù…Ù† Ø§Ù„ØªÙˆØ¨ÙŠÙƒ\n",
    "        topic_doc_indices = [j for j, t in enumerate(topics) if t == predicted_topic]\n",
    "        if not topic_doc_indices:\n",
    "            results[query_id] = []\n",
    "            continue\n",
    "\n",
    "        topic_doc_embeddings = [doc_embeddings[j] for j in topic_doc_indices]\n",
    "        topic_doc_ids = [doc_ids[j] for j in topic_doc_indices]\n",
    "\n",
    "        # 3ï¸âƒ£ Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡\n",
    "        similarities = cosine_similarity([query_embedding], topic_doc_embeddings)[0]\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "        results[query_id] = [\n",
    "            (topic_doc_ids[j], float(similarities[j])) for j in top_indices\n",
    "        ]\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {output_path}\")\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T11:59:51.724295Z",
     "start_time": "2025-07-07T10:25:01.330728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "match_queries_by_topic(\n",
    "    docs_topic_path=r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\TopicResults\\merged_topics_1500.joblib\",\n",
    "    docs_embedding_path=r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Data Representation\\Bert\\beir\\quora\\test\\doc\\bert_embedding.joblib\",\n",
    "    queries_embedding_path=r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Processing\\Bertquery\\BEIR\\quora\\test\\query_embeddings\\bert_query_embeddings.joblib\",\n",
    "    output_path=r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\Evaluation\\bert_topic_results.json\",\n",
    "    top_k=100\n",
    ")\n"
   ],
   "id": "27da0f493009cfc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª BERTopic + BERT embeddings Ù„Ù„ÙˆØ«Ø§Ø¦Ù‚...\n",
      "ğŸ§  Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØ¨ÙŠÙƒØ§Øª: 5\n",
      "ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª: 10000, Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚: 522931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [1:33:38<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\Evaluation\\bert_topic_results.json\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:14:24.022474Z",
     "start_time": "2025-07-06T19:13:34.762212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "match_queries_by_topic(\n",
    "    docs_topic_path=r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\TopicResults\\antique_train_bertopic_results.joblib\",\n",
    "    docs_embedding_path=r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Data Representation\\Bert\\antique\\train\\doc\\bert_embedding.joblib\",\n",
    "    queries_embedding_path=r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Processing\\Bertquery\\antique\\train\\query_embeddings\\bert_query_embeddings.joblib\",\n",
    "    output_path=r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\Evaluation\\bert_topic_results_antique.json\",\n",
    "    top_k=100\n",
    ")\n"
   ],
   "id": "a2654fbc27b86b51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª BERTopic + BERT embeddings Ù„Ù„ÙˆØ«Ø§Ø¦Ù‚...\n",
      "ğŸ§  Ø¹Ø¯Ø¯ Ø§Ù„ØªÙˆØ¨ÙŠÙƒØ§Øª: 4753\n",
      "ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª: 176, Ø¹Ø¯Ø¯ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚: 401768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 118/176 [00:05<00:02, 19.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmatch_queries_by_topic\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdocs_topic_path\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mC:\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mUsers\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mAzzam\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mPycharmProjects\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mPythonProject\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mTopicResults\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mantique_train_bertopic_results.joblib\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdocs_embedding_path\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mC:\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mUsers\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mAzzam\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mPycharmProjects\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mPythonProject\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mData Representation\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mBert\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mantique\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mtrain\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mdoc\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mbert_embedding.joblib\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mqueries_embedding_path\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mC:\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mUsers\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mAzzam\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mPycharmProjects\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mPythonProject\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mQuery Processing\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mBertquery\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mantique\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mtrain\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mquery_embeddings\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mbert_query_embeddings.joblib\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mC:\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mUsers\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mAzzam\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mPycharmProjects\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mPythonProject\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mQuery Matching & Ranking\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mEvaluation\u001B[39;49m\u001B[33;43m\\\u001B[39;49m\u001B[33;43mbert_topic_results_antique.json\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m100\u001B[39;49m\n\u001B[32m      7\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 45\u001B[39m, in \u001B[36mmatch_queries_by_topic\u001B[39m\u001B[34m(docs_topic_path, docs_embedding_path, queries_embedding_path, output_path, top_k)\u001B[39m\n\u001B[32m     42\u001B[39m predicted_topic = topic_ids[best_topic_index]\n\u001B[32m     44\u001B[39m \u001B[38;5;66;03m# 2ï¸âƒ£ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø¶Ù…Ù† Ø§Ù„ØªÙˆØ¨ÙŠÙƒ\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m topic_doc_indices = \u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtopics\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredicted_topic\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     46\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m topic_doc_indices:\n\u001B[32m     47\u001B[39m     results[query_id] = []\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 45\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m     42\u001B[39m predicted_topic = topic_ids[best_topic_index]\n\u001B[32m     44\u001B[39m \u001B[38;5;66;03m# 2ï¸âƒ£ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø¶Ù…Ù† Ø§Ù„ØªÙˆØ¨ÙŠÙƒ\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m topic_doc_indices = [j \u001B[38;5;28;01mfor\u001B[39;00m j, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(topics) \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredicted_topic\u001B[49m]\n\u001B[32m     46\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m topic_doc_indices:\n\u001B[32m     47\u001B[39m     results[query_id] = []\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T12:00:06.488886Z",
     "start_time": "2025-07-07T12:00:00.220698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import ir_datasets\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ qrels Ù…Ù† BEIR Quora\n",
    "dataset = ir_datasets.load(\"beir/quora/test\")\n",
    "qrels = defaultdict(set)\n",
    "for qrel in dataset.qrels_iter():\n",
    "    if int(qrel.relevance) > 0:\n",
    "        qrels[qrel.query_id].add(qrel.doc_id)\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ù† Ù…Ù„Ù JSON\n",
    "with open(r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\Evaluation\\bert_topic_results.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…\n",
    "def precision_at_k(retrieved, relevant, k):\n",
    "    retrieved_k = retrieved[:k]\n",
    "    if not retrieved_k:\n",
    "        return 0.0\n",
    "    return len([doc for doc in retrieved_k if doc in relevant]) / k\n",
    "\n",
    "def recall_at_k(retrieved, relevant, k):\n",
    "    retrieved_k = retrieved[:k]\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    return len([doc for doc in retrieved_k if doc in relevant]) / len(relevant)\n",
    "\n",
    "def average_precision(retrieved, relevant, k):\n",
    "    score = 0.0\n",
    "    hits = 0\n",
    "    for i, doc_id in enumerate(retrieved[:k], start=1):\n",
    "        if doc_id in relevant:\n",
    "            hits += 1\n",
    "            score += hits / i\n",
    "    return score / min(len(relevant), k) if relevant else 0.0\n",
    "\n",
    "def dcg(retrieved, relevant, k):\n",
    "    return sum([(1 if retrieved[i] in relevant else 0) / np.log2(i + 2) for i in range(min(len(retrieved), k))])\n",
    "\n",
    "def idcg(relevant, k):\n",
    "    return sum([1 / np.log2(i + 2) for i in range(min(len(relevant), k))])\n",
    "\n",
    "def ndcg_at_k(retrieved, relevant, k):\n",
    "    dcg_val = dcg(retrieved, relevant, k)\n",
    "    idcg_val = idcg(relevant, k)\n",
    "    return dcg_val / idcg_val if idcg_val > 0 else 0.0\n",
    "\n",
    "# Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª\n",
    "k = 10\n",
    "precisions, recalls, maps, ndcgs = [], [], [], []\n",
    "\n",
    "for qid, retrieved_docs in tqdm(results.items(), desc=\"ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª\"):\n",
    "    retrieved_doc_ids = [doc_id for doc_id, _ in retrieved_docs]\n",
    "    relevant_doc_ids = qrels[qid]\n",
    "\n",
    "    precisions.append(precision_at_k(retrieved_doc_ids, relevant_doc_ids, k))\n",
    "    recalls.append(recall_at_k(retrieved_doc_ids, relevant_doc_ids, k))\n",
    "    maps.append(average_precision(retrieved_doc_ids, relevant_doc_ids, k))\n",
    "    ndcgs.append(ndcg_at_k(retrieved_doc_ids, relevant_doc_ids, k))\n",
    "\n",
    "# Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©\n",
    "evaluation_results = {\n",
    "    \"Precision@10\": round(np.mean(precisions), 4),\n",
    "    \"Recall@10\": round(np.mean(recalls), 4),\n",
    "    \"MAP@10\": round(np.mean(maps), 4),\n",
    "    \"NDCG@10\": round(np.mean(ndcgs), 4),\n",
    "}\n",
    "\n",
    "print(\"ğŸ“ˆ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:\")\n",
    "for metric, value in evaluation_results.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ],
   "id": "2956d242be1b2f4a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 14558.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:\n",
      "Precision@10: 0.0484\n",
      "Recall@10: 0.3382\n",
      "MAP@10: 0.2935\n",
      "NDCG@10: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T15:35:44.288570Z",
     "start_time": "2025-07-05T15:35:43.905629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import ir_datasets\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "qrels_path = r\"C:\\Users\\Azzam\\.ir_datasets\\antique\\test\\qrels\"\n",
    "qrels = defaultdict(set)\n",
    "\n",
    "with open(qrels_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 4:\n",
    "            qid, _, docid, rel = parts\n",
    "            if int(rel) > 0:\n",
    "                qrels[qid].add(docid)\n",
    "\n",
    "# ØªØ­Ù…ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ù† Ù…Ù„Ù JSON\n",
    "with open(r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\Evaluation\\bert_topic_results_antique.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…\n",
    "def precision_at_k(retrieved, relevant, k):\n",
    "    retrieved_k = retrieved[:k]\n",
    "    if not retrieved_k:\n",
    "        return 0.0\n",
    "    return len([doc for doc in retrieved_k if doc in relevant]) / k\n",
    "\n",
    "def recall_at_k(retrieved, relevant, k):\n",
    "    retrieved_k = retrieved[:k]\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    return len([doc for doc in retrieved_k if doc in relevant]) / len(relevant)\n",
    "\n",
    "def average_precision(retrieved, relevant, k):\n",
    "    score = 0.0\n",
    "    hits = 0\n",
    "    for i, doc_id in enumerate(retrieved[:k], start=1):\n",
    "        if doc_id in relevant:\n",
    "            hits += 1\n",
    "            score += hits / i\n",
    "    return score / min(len(relevant), k) if relevant else 0.0\n",
    "\n",
    "def dcg(retrieved, relevant, k):\n",
    "    return sum([(1 if retrieved[i] in relevant else 0) / np.log2(i + 2) for i in range(min(len(retrieved), k))])\n",
    "\n",
    "def idcg(relevant, k):\n",
    "    return sum([1 / np.log2(i + 2) for i in range(min(len(relevant), k))])\n",
    "\n",
    "def ndcg_at_k(retrieved, relevant, k):\n",
    "    dcg_val = dcg(retrieved, relevant, k)\n",
    "    idcg_val = idcg(relevant, k)\n",
    "    return dcg_val / idcg_val if idcg_val > 0 else 0.0\n",
    "\n",
    "# Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª\n",
    "k = 10\n",
    "precisions, recalls, maps, ndcgs = [], [], [], []\n",
    "\n",
    "for qid, retrieved_docs in tqdm(results.items(), desc=\"ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª\"):\n",
    "    retrieved_doc_ids = [doc_id for doc_id, _ in retrieved_docs]\n",
    "    relevant_doc_ids = qrels[qid]\n",
    "\n",
    "    precisions.append(precision_at_k(retrieved_doc_ids, relevant_doc_ids, k))\n",
    "    recalls.append(recall_at_k(retrieved_doc_ids, relevant_doc_ids, k))\n",
    "    maps.append(average_precision(retrieved_doc_ids, relevant_doc_ids, k))\n",
    "    ndcgs.append(ndcg_at_k(retrieved_doc_ids, relevant_doc_ids, k))\n",
    "\n",
    "# Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©\n",
    "evaluation_results = {\n",
    "    \"Precision@10\": round(np.mean(precisions), 4),\n",
    "    \"Recall@10\": round(np.mean(recalls), 4),\n",
    "    \"MAP@10\": round(np.mean(maps), 4),\n",
    "    \"NDCG@10\": round(np.mean(ndcgs), 4),\n",
    "}\n",
    "\n",
    "print(\"ğŸ“ˆ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:\")\n",
    "for metric, value in evaluation_results.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ],
   "id": "f88612a554cc16f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [00:00<00:00, 24401.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:\n",
      "Precision@10: 0.2909\n",
      "Recall@10: 0.0807\n",
      "MAP@10: 0.2138\n",
      "NDCG@10: 0.3375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
