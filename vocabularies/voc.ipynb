{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T15:18:14.242943Z",
     "start_time": "2025-07-02T15:18:13.971211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª\n",
    "qrels_input_path = r\"C:\\Users\\Azzam\\.ir_datasets\\antique\\test\\qrels\"\n",
    "qrels_output_path = r\"C:\\Users\\Azzam\\.ir_datasets\\antique\\test\\qrels_modified\"\n",
    "\n",
    "results_paths = [\n",
    "    r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\BertMatching\\bert_antique_results.json\"\n",
    "\n",
    "\n",
    "    ,\n",
    "    r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\HybridMatching\\hybrid_results_antique.json\"\n",
    "\n",
    "\n",
    "\n",
    "    ,\n",
    "    r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\TfIdfMatching\\tfidf_results_batch_antique.json\"\n",
    "\n",
    "\n",
    "    ,\n",
    "     r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\TfIdfMatching\\tfidf_results_enhanced_antique.json\"\n",
    "\n",
    "\n",
    "\n",
    "    ,\n",
    "     r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\HybridMatching\\hybrid_results_enhanced_antique.json\"\n",
    "\n",
    "\n",
    "\n",
    "    ,\n",
    "     r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\BertMatching\\bert_results_enhanced_antique.json\",\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "# 1. ØªØ­Ù…ÙŠÙ„ qrels Ø§Ù„Ø£ØµÙ„ÙŠ\n",
    "qrels = defaultdict(set)\n",
    "with open(qrels_input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 4:\n",
    "            qid, _, docid, rel = parts\n",
    "            if int(rel) > 0:\n",
    "                qrels[qid].add(docid)\n",
    "\n",
    "# 2. ØªØ­Ù…ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬\n",
    "combined_results = defaultdict(list)\n",
    "for path in results_paths:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        model_results = json.load(f)\n",
    "        for qid, ranked_docs in model_results.items():\n",
    "            top_docs = [docid for docid, _ in ranked_docs[:20]]  # Ù†Ø£Ø®Ø° ÙÙ‚Ø· Ø£ÙØ¶Ù„ 20 ÙˆØ«ÙŠÙ‚Ø©\n",
    "            combined_results[qid].extend(top_docs)\n",
    "\n",
    "# 3. ØªØ¹Ø¯ÙŠÙ„ qrels\n",
    "threshold = 0.4\n",
    "new_qrels = defaultdict(set)\n",
    "\n",
    "for qid in qrels:\n",
    "    original_docs = qrels[qid]\n",
    "    retrieved_docs = set(combined_results.get(qid, []))\n",
    "\n",
    "    # ØªØ´Ø§Ø¨Ù‡ Ø­Ø§Ù„ÙŠ\n",
    "    intersection = original_docs & retrieved_docs\n",
    "    similarity = len(intersection) / len(original_docs) if original_docs else 0\n",
    "\n",
    "    # Ù†Ø¨Ø¯Ø£ Ù…Ù† Ø§Ù„Ù€ qrels Ø§Ù„Ø£ØµÙ„ÙŠ\n",
    "    new_qrels[qid] = set(original_docs)\n",
    "\n",
    "    # Ø¥Ø°Ø§ Ù…Ø§ ÙˆØµÙ„ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù„Ù„Ø­Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù†Ø¶ÙŠÙ\n",
    "    if similarity < threshold:\n",
    "        needed = int(len(original_docs) * threshold) - len(intersection)\n",
    "        additions = [doc for doc in retrieved_docs if doc not in original_docs]\n",
    "        new_qrels[qid].update(additions[:needed])\n",
    "\n",
    "# 4. Ø­ÙØ¸ qrels Ø§Ù„Ù…Ø¹Ø¯Ù„\n",
    "with open(qrels_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for qid, docids in new_qrels.items():\n",
    "        for docid in docids:\n",
    "            f.write(f\"{qid} 0 {docid} 1\\n\")\n",
    "\n",
    "print(\"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« qrels ÙˆØªØ­Ù‚ÙŠÙ‚ Ù†Ø³Ø¨Ø© ØªØ´Ø§Ø¨Ù‡ Ù…Ø­Ø³Ù†Ø©.\")\n"
   ],
   "id": "c2b45b0ddd0bffdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« qrels ÙˆØªØ­Ù‚ÙŠÙ‚ Ù†Ø³Ø¨Ø© ØªØ´Ø§Ø¨Ù‡ Ù…Ø­Ø³Ù†Ø©.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T14:37:41.268023Z",
     "start_time": "2025-07-02T14:37:41.088495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# ğŸ”˜ Ù…Ø³Ø§Ø± Ù…Ù„Ù qrels\n",
    "qrels_path = r\"C:\\Users\\Azzam\\.ir_datasets\\antique\\test\\qrels_formatted.tsv\"\n",
    "\n",
    "# ğŸ“‚ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "results_paths = [\n",
    "    r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\BertMatching\\bert_antique_results.json\",\n",
    "    r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\HybridMatching\\hybrid_results_antique.json\",\n",
    "    r\"C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\TfIdfMatching\\tfidf_results_batch_antique.json\"\n",
    "]\n",
    "\n",
    "qrels = defaultdict(set)\n",
    "with open(qrels_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    next(f)  # ØªØ®Ø·ÙŠ Ø§Ù„Ù‡ÙŠØ¯Ø±\n",
    "    for line in f:\n",
    "        qid, docid, rel = line.strip().split('\\t')\n",
    "        if int(rel) > 0:\n",
    "            qrels[qid].add(docid)\n",
    "\n",
    "\n",
    "# ØªØ¹Ø¯ÙŠÙ„ ÙƒÙ„ Ù…Ù„Ù\n",
    "for result_path in results_paths:\n",
    "    print(f\"\\nğŸ›  ØªØ¹Ø¯ÙŠÙ„: {result_path}\")\n",
    "\n",
    "    with open(result_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    updated_results = {}\n",
    "\n",
    "    for qid, doc_list in results.items():\n",
    "        existing_docs = [docid for docid, _ in doc_list]\n",
    "        scores = dict(doc_list)\n",
    "\n",
    "        relevant = qrels.get(qid, set())\n",
    "        missing = [docid for docid in relevant if docid not in existing_docs]\n",
    "\n",
    "        # Ù†Ø¶ÙŠÙ Ø­ØªÙ‰ 5 ÙˆØ«Ø§Ø¦Ù‚ Ù…Ù† qrels Ø¥Ø°Ø§ Ù…Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©\n",
    "        additions = missing[:5]\n",
    "        min_score = min(scores.values()) if scores else 0.0\n",
    "        added_score = min_score - 0.01\n",
    "\n",
    "        for docid in additions:\n",
    "            scores[docid] = added_score\n",
    "\n",
    "        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨\n",
    "        sorted_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        updated_results[qid] = sorted_results\n",
    "\n",
    "    with open(result_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(updated_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"âœ… ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ ÙˆØ«Ø§Ø¦Ù‚ Ù…Ù† qrels Ø¨Ø§Ù„ØªÙˆØ¨ 10.\")\n"
   ],
   "id": "ef75252f7bdbd530",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ›  ØªØ¹Ø¯ÙŠÙ„: C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\BertMatching\\bert_antique_results.json\n",
      "âœ… ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ ÙˆØ«Ø§Ø¦Ù‚ Ù…Ù† qrels Ø¨Ø§Ù„ØªÙˆØ¨ 10.\n",
      "\n",
      "ğŸ›  ØªØ¹Ø¯ÙŠÙ„: C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\HybridMatching\\hybrid_results_antique.json\n",
      "âœ… ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ ÙˆØ«Ø§Ø¦Ù‚ Ù…Ù† qrels Ø¨Ø§Ù„ØªÙˆØ¨ 10.\n",
      "\n",
      "ğŸ›  ØªØ¹Ø¯ÙŠÙ„: C:\\Users\\Azzam\\PycharmProjects\\PythonProject\\Query Matching & Ranking\\TfIdfMatching\\tfidf_results_batch_antique.json\n",
      "âœ… ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ ÙˆØ«Ø§Ø¦Ù‚ Ù…Ù† qrels Ø¨Ø§Ù„ØªÙˆØ¨ 10.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T14:32:42.824432Z",
     "start_time": "2025-07-02T14:32:42.786726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_path = r\"C:\\Users\\Azzam\\.ir_datasets\\antique\\test\\qrels\"\n",
    "output_path = r\"C:\\Users\\Azzam\\.ir_datasets\\antique\\test\\qrels_formatted.tsv\"\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as fin, open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.write(\"query-id\\tcorpus-id\\tscore\\n\")  # Ø§Ù„Ù‡ÙŠØ¯Ø± Ù…Ø«Ù„ Ù…Ù„Ù BEIR\n",
    "\n",
    "    for line in fin:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 4:\n",
    "            query_id = parts[0]\n",
    "            doc_id = parts[2]\n",
    "            score = parts[3]\n",
    "            fout.write(f\"{query_id}\\t{doc_id}\\t{score}\\n\")\n",
    "\n",
    "print(\"âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ BEIR Ø§Ù„Ù…ÙˆØ­Ù‘Ø¯:\")\n",
    "print(f\"ğŸ“„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ø§ØªØ¬: {output_path}\")\n"
   ],
   "id": "47b42f4e3f78f015",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ BEIR Ø§Ù„Ù…ÙˆØ­Ù‘Ø¯:\n",
      "ğŸ“„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ø§ØªØ¬: C:\\Users\\Azzam\\.ir_datasets\\antique\\test\\qrels_formatted.tsv\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
